So the challenge is to protect user data from malicious adversaries but
at the same time making users findable for other legitimate users.
To distinguish between these two cases, we assume that legitimate users
possess more information about a target user than the adversary.
Then a knowledge threshold can be enforced using cryptographic techniques, to
guarantee that a user can only be found if the party searching for her
can present enough details about her (\enquote{find me if you know enough about
me}).

Two protocols' implementations are presented by \citet{ThresholdUserSearch} 
that have different advantages and disadvantages.
Neither rely on any central repository of user data but are suitable to be 
implemented in a completely decentralized way using \iac{DHT}.
This avoids the biggest risk to user data: the leakage of a central database 
with sensitive information about a large number of people.

The proposed protocols allow users to register their identifiers (e.g.\ 
links to their profile pages, e-mail addresses or other contact
information) and specify the required knowledge that is needed to find
this information (e.g.\  name, city, workplace and date of birth).
One implementation guarantees this knowledge-threshold by encoding the
storage location of the registered user identifiers using the required
knowledge attributes.
Only users that know these attributes can construct a valid lookup request for 
the \ac{DHT} that will return the desired user identifier.
The other protocol stores user identifiers encrypted in the \ac{DHT} and uses 
threshold secret-sharing techniques to guarantee that no user with less than 
the required number of attributes can decrypt a stored identifier.

Neither protocol can provide perfect protection.
In the worst-case of a targeted attack, an adversary with profound background 
knowledge about the target user will likely succeed.
For example, we cannot protect the user identifier if the adversary knows as 
many attributes about the target user as legitimate users do.
At the same time, both schemes protect the users fairly well from large-scale 
crawling attacks as the search space of all possible attribute combinations is 
too large to brute-force and the protocols transform the registered user data 
in such a way that inferences from the publicly stored data are infeasible.
Even if the adversary focuses her effort to only crawl the data of a specified 
subset of the user-base (e.g.\ all persons working at a specific organization), 
the proposed protocols offer good protection. 

The knowledge-threshold is an individual user parameter, so users that
consider themselves to be more exposed to risks can choose a higher
knowledge-threshold to increase their protection at the cost of a lower
usability, as a higher threshold makes it harder for other legitimate
users to find them.
In that sense, the presented protocols allow users to individually balance 
their findability and privacy requirements.

